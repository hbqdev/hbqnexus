{
  "items": [
    {
      "id": "94c7f8bf-94b1-455a-a597-e7a300924284",
      "url": "https://www.theseedsofscience.pub/p/your-iq-isnt-160-no-ones-is",
      "type": "article",
      "title": "Your IQ isn't 160. No one's is.",
      "content": "<div><article><div><p><em><span>Erik Hoel is a neuroscientist and </span><a href=\"https://www.theintrinsicperspective.com/\">writer</a><span> with an IQ of 159. </span></em></p><p><em><span>ICYMI: </span><a href=\"https://www.theseedsofscience.pub/p/bucks-for-blogs-announcing-the-subscription\">Bucks for Science Blogs: Announcing the Subscription Revenue Sharing Program</a></em></p><div><figure><a href=\"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe8b61dd6-87aa-4536-87d4-cc5458b3904c_460x438.png\"><div><picture><source sizes=\"100vw\" srcset=\"https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe8b61dd6-87aa-4536-87d4-cc5458b3904c_460x438.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe8b61dd6-87aa-4536-87d4-cc5458b3904c_460x438.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe8b61dd6-87aa-4536-87d4-cc5458b3904c_460x438.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe8b61dd6-87aa-4536-87d4-cc5458b3904c_460x438.png 1456w\" type=\"image/webp\"><img srcset=\"https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe8b61dd6-87aa-4536-87d4-cc5458b3904c_460x438.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe8b61dd6-87aa-4536-87d4-cc5458b3904c_460x438.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe8b61dd6-87aa-4536-87d4-cc5458b3904c_460x438.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe8b61dd6-87aa-4536-87d4-cc5458b3904c_460x438.png 1456w\" src=\"https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fe8b61dd6-87aa-4536-87d4-cc5458b3904c_460x438.png\"></picture></div></a></figure></div><p>One cannot help but run into people who clearly fantasize about the following scenario: All the great geniuses of the past sit down and take some sort of culture-invariant IQ test, and then we get to line up the numbers and compare them, finally settling once and for all who was the greatest genius of humanity.</p><p>In this fantasy they imagine Voltaire in his study, finishing his fortieth cup of coffee (he used to drink around 50 a day), sharpening a #2 pencil at his desk, getting ready to fill in all those little bubbles. Is it A? Or D? Hmm, hasn’t been A in a while. . .</p><p>How the great geniuses of the past would do filling in these ovals perennially fascinates. Einstein would get a 160! Darwin a 180! Aristotle, 190! And while speculating about the numerical ranking of the long dead, IQ enthusiasts will refer quite regularly to IQs of 150 or even 200, presumably thinking that intelligence can actually be tracked at those numbers. You can find all sorts of SEO traps that give nonsensical rankings like this:</p><div><figure><a href=\"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7533843b-8da8-41c2-81c1-c8ec08e08e3f_1434x532.png\"><div><picture><source sizes=\"100vw\" srcset=\"https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7533843b-8da8-41c2-81c1-c8ec08e08e3f_1434x532.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7533843b-8da8-41c2-81c1-c8ec08e08e3f_1434x532.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7533843b-8da8-41c2-81c1-c8ec08e08e3f_1434x532.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7533843b-8da8-41c2-81c1-c8ec08e08e3f_1434x532.png 1456w\" type=\"image/webp\"><img srcset=\"https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7533843b-8da8-41c2-81c1-c8ec08e08e3f_1434x532.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7533843b-8da8-41c2-81c1-c8ec08e08e3f_1434x532.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7533843b-8da8-41c2-81c1-c8ec08e08e3f_1434x532.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7533843b-8da8-41c2-81c1-c8ec08e08e3f_1434x532.png 1456w\" src=\"https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F7533843b-8da8-41c2-81c1-c8ec08e08e3f_1434x532.png\"></picture></div></a></figure></div><p>So pervasive is this thinking that typing into Google “Did Einstein ever take an IQ test?” gives this result as Google’s own sent-to-the-top answer:</p><blockquote><p>Einstein never took a modern IQ test, but it's believed that he had an IQ of 160, the same score as Hawking. Only 1 percent of those who sit the Mensa test achieve the maximum mark, and the average score is 100. A 'genius' test score is generally considered to be anything over 140.</p></blockquote><p>Wow! Except that</p><p><span>In the above Google-approved quote, the scores for both Einstein and Hawking are imaginary. Here’s from </span><em><a href=\"https://www.newsweek.com/what-stephen-hawkings-iq-score-late-physicist-called-people-who-care-losers-843895\">Newsweek</a></em><span>:</span></p><blockquote><p><span>When asked in a 2004 interview with </span><em><a href=\"https://www.nytimes.com/2004/12/12/magazine/the-science-of-secondguessing.html\">The New York Times</a></em><span> what his IQ is, Hawking gave a curt reply: \"I have no idea. People who boast about their IQ are losers.\"</span></p></blockquote><p><span>Now, it’s worth noting that if you want to know your own IQ, and you’ve never taken an official test, just think about whatever your SAT scores were. The two are </span><a href=\"https://journals.sagepub.com/doi/full/10.1111/j.0956-7976.2004.00687.x?casa_token=NQuQDI9kSFkAAAAA%3A39BR8cUxFZhJ_fatyxDyXmAIv1xff0vlZmUW1uB9tQ1rgaqzJHv6_SWn0FdDCD6i6avf4jNMv_xwrA\">very well-correlated</a><span>. If you “test well” then you probably have a high IQ (and people are quite comfortable </span><a href=\"https://theuntangler.wordpress.com/2023/03/25/estimating-scott-alexanders-iq/\">estimating</a><span> IQ off of test scores in the modern age).</span></p><p><span>But this gives us an easy question: did Einstein and other great geniuses of the past “test well?” If they did, then they probably had a high IQ. This method isn’t perfect, but since we lack any actual IQ data on the majority of historical geniuses, it can at least point us in the right direction. E.g., </span><a href=\"https://www.washingtonpost.com/news/answer-sheet/wp/2016/02/11/was-albert-einstein-really-a-bad-student-who-failed-math/\">Einstein</a></p><blockquote><p><span>did flunk the entrance exam to the Zurich Polytechnic when he first took it — when he was about 1 1/2 years away from graduating high school, at age 16, and hadn’t had a lot of French, the language in which the exam was given. He did fine on the math section but failed the language, botany and zoology sections, </span><a href=\"http://www.history.com/topics/einsteins-life-facts-and-fiction\">according to history.com</a><span>. A 1984 </span><a href=\"http://www.nytimes.com/1984/02/14/science/einstein-revealed-as-brilliant-in-youth.html?pagewanted=all\">New York Times story</a><span> says that the essay Einstein wrote for this exam was “full of errors” but pointed to his later interests.</span></p></blockquote><p>And yes, he was taking it in a second language, and trying to get into college early, but still, failing botany and zoology? Just “fine” on the math section? Hard to imagine most AP students now-a-days getting those sort of scores. While we can’t possibly know if the standardized tests at the time are as closely correlated to IQ as SAT scores are today, surely they correlate to some degree?</p><p><span>What about Einstein’s grades? Current evidence tells us that grades are “</span><a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5127298/#\">strongly positively correlated</a><span>” with IQ. If someone gets very high grades, we’d expect them to score high on an IQ test. And while there certainly may be differences between now and then, Einstein was not getting top grades. Here’s his high school report card, with grades spanning from 1-6 (not all sixes):</span></p><p>One reply might be that Einstein was merely a mathematical genius, and so of course he didn’t score well on other subjects. Yet, his grades in college, when he could take mostly mathematical subjects, are around the same—in fact he didn’t get a single maximum grade. This is again on a 1-6 scale:</p><p>Einstein seemed to be a mostly B+ student in college, even in math. My guess is this holds for most historical figures now widely considered geniuses, and only in rare cases would the historical record show them consistently acing tests and getting extremely high GPAs in their high schools, things which are, in the modern day, strongly associated with very high IQ.</p><p>If we play this game of hypothetical oval-filling, just based on his actual academic record I would estimate that Einstein would get in the 700s on the math section of the SATs, and maybe in the 600s on the verbal section. Ball-parking it, as one must, I think Einstein’s IQ was therefore probably more around 120 or 130 than 160. Indeed very high! But maybe not even “genius level.” He would have scored similarly to Feynman, one of the few geniuses we for sure have a modern IQ for, which was “merely” 125. This conclusion fits well with how</p><p><span>Consider a book from the 1950s, </span><em>The Making of a Scientist</em><span> by psychologist and Harvard professor </span><a href=\"https://en.wikipedia.org/wiki/Anne_Roe\">Anne Roe</a><span>, in which she supposedly measured the IQ of Nobel Prize winners. The book is occasionally </span><a href=\"https://infoproc.blogspot.com/2008/07/annals-of-psychometry-iqs-of-eminent.html\">dug up</a><span> and used as evidence that Nobel Prize winners have an extremely high IQ, like 160 plus. But it’s really an example of how many studies of genius are methodologically deeply flawed. In the book, the claims and numbers verge on the obviously ridiculous (e.g., Roe cites someone who claims that Goethe had an IQ of 210, noting that this beat out Leibniz at 205).</span></p><p>Yet, Roe never used an official IQ tests on her subjects, the Nobel Prize winners. Rather, she made up her test, simply a timed test that used SAT questions of the day. Why? Because most IQ tests have ceilings (you can only score like a 130 or 140 on them) and Roe thought—without any evidence or testing—that would be too low for the Nobel Prize winners. And while she got some help with this from the organization that created the SATs, she admits:</p><blockquote><p>The test I used is not one that has been used before, at least in this form.</p></blockquote><p>And furthermore:</p><blockquote><p>I was not particularly concerned at the outset over the fact that I had no norms for this test. That is, I had no idea what any other population would do on the same test.</p></blockquote><p>In other words, she had an untested set of SAT questions that she gave to Nobel prize winners not knowing how anyone else would do on them. This is pretty problematic. Normally IQ tests try to achieve some form of group-level neutrality; e.g., many of the major modern IQ tests are constructed from the outset so as not show any average difference between male and female takers, to be as culturally-invariant as possible, etc. And while Roe didn’t publish without any comparison group to her chosen geniuses whatsoever, the comparison that she did use was only a graduating class of PhD students (sample size unknown, as far as I can tell) who also took some other more standard IQ tests of the day, and she basically just converted from their scores on the other tests to scores on her make-shift test of SAT questions. Yet, here are the raw numbers of how the Nobel-prize winners do on the test she created:</p><div><figure><a href=\"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff69e20ca-cccc-4819-b46e-54acdd404bf8_816x380.png\"><div><picture><source sizes=\"100vw\" srcset=\"https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff69e20ca-cccc-4819-b46e-54acdd404bf8_816x380.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff69e20ca-cccc-4819-b46e-54acdd404bf8_816x380.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff69e20ca-cccc-4819-b46e-54acdd404bf8_816x380.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff69e20ca-cccc-4819-b46e-54acdd404bf8_816x380.png 1456w\" type=\"image/webp\"><img srcset=\"https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff69e20ca-cccc-4819-b46e-54acdd404bf8_816x380.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff69e20ca-cccc-4819-b46e-54acdd404bf8_816x380.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff69e20ca-cccc-4819-b46e-54acdd404bf8_816x380.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff69e20ca-cccc-4819-b46e-54acdd404bf8_816x380.png 1456w\" src=\"https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff69e20ca-cccc-4819-b46e-54acdd404bf8_816x380.png\"></picture></div></a></figure></div><p>Notice anything? The Nobel Prize winners all scored rather average. In fact, pretty low, in some cases. But Roe then goes on to claim that their IQ is extremely high, based on her statistical transformations:</p><blockquote><p>I must caution that these equivalents have been arrived at by a series of statistical transformations based on assumptions which are generally valid for this type of material but which have not been specifically checked for these data. Nevertheless I believe that they are meaningful and a fair guide to what the situation is. The median score of this group on this verbal test is approximately equivalent to an IQ of 166.</p></blockquote><p>Wait a minute. How did this conversion to a median IQ of 166 take place? After all, the scientists are scoring in the middle of the range on the test. They are getting a lot of questions wrong. E.g., Biologists who won the Nobel Prize got a 56.6 on the Verbal but we know that was far from the maximum score, Experimental Physicists got an even lower 46.6, etc. How then did she arrive at the group altogether having an astoundingly-high median verbal IQ of 166? Assuming that those at the upper range of scoring got close to most of the questions right (she mentions this is true, some only missed 4-10 questions at the maximum range), then how can getting only roughly two-thirds of the questions right translate to an IQ in the 160s?</p><p>Perhaps these SAT questions were just impossibly hard? Judge for yourself. Here’s one of the two examples she gives of the type of questions the Nobel Prize winners answered:</p><blockquote><p>In each item in the first section, four words were given, and the subject had to pick the two which were most nearly opposite in meaning and underline them.</p><p><span>Here is one of the items: </span><strong>1.</strong><span> Predictable </span><strong>2.</strong><span> Precarious </span><strong>3.</strong><span> Stable </span><strong>4.</strong><span> Laborious.</span></p></blockquote><p>This. . . isn’t very hard (spoiler: 2 &amp; 3). So the conclusion of a median verbal IQ of 166 is deeply questionable, and totally reliant on this mysterious conversion she performed.</p><p>This sort of experimental setup would never fly today (my guess is the statistical conversion had all sorts of problems, e.g., Roe mentions extraordinarily high IQ numbers for PhD students at the time that don’t make sense, like an avg. IQ of 140). A far more natural reading of her results is to remove the mysterious conversion and look at the raw data, which is that the Nobel-prize-winning scientists scored well but not amazingly on SAT questions, indicating that Nobel Prize winners would get test scores above average but would not ace the SATs, since the average was far below the top of the possible range.</p><p><span>Now that I’ve finished being hard on poor Anne Roe, long deceased and unable to defend herself, an interesting woman who lived and worked when science was more of a Wild West, and who was the 9th tenured female professor at Harvard, it’s worth pointing out that a lot of the other stuff in her book is fascinating, like her examination of Nobel Prize winners’ habits and backgrounds. So to be fair to those once here and now gone, I’ll let Anne end this section in her own words, written in a footnote of </span><em>The Making of a Scientist</em><span>:</span></p><blockquote><p>It is now being considered whether we might not do better to work at the problem in a different way and try to include other factors such as motivation. I strongly endorse this. For some time I have been convinced that there is no such thing as “creative ability” as a unit factor which some people have and some do not, and I strongly suspect that I will soon come to the conclusion that the same thing applies to intellectual ability as a thing apart.</p></blockquote><p>Anne was right, because we now know that</p><p><span>Practice works wonders for IQ tests, just as it does the SATs. There is a limited set of types of questions IQ tests ask, always variations on a theme. The more you familiarize yourself with Raven’s Progressive Matrices, the better you’ll do on them. Even just practice in general problem solving can boost IQ scores. Consider an </span><a href=\"https://www.sciencedirect.com/science/article/abs/pii/0160289686900164\">experiment</a><span> conducted by R. Kvashchev in former Yugoslavia:</span></p><blockquote><p><span>In an effort to improve performance of high school students on intelligence tests, a large-scale study involving 296 students was carried out. Members of the experimental group (</span><em>N</em><span> = 149) were given exercises in creative problem solving 3 to 4 times a week over a period of 3 years and performance was assessed on four occasions. . . The test battery contained 28 measures of fluid and crystallized intelligence.</span></p></blockquote><p><span>In a reanalysis of the data published in 2020 in the </span><em><a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7709590/pdf/jintelligence-08-00041.pdf\">Journal of Intelligence</a></em><span> the authors argued that</span></p><blockquote><p>with the properly defined measures of fluid and crystallized intelligence, the experimental group showed a 15 IQ points higher increase than the control group. We concluded that prolonged intensive training in creative problem-solving can lead to substantial and positive effects on intelligence during late adolescence (ages 18–19).</p></blockquote><p><span>Regardless of if IQ numbers really are this changeable so late in development, I think people who supposedly score incredibly high on specialized IQ tests, like </span><a href=\"https://www.youtube.com/watch?v=6WKsr4b_7NY\">Chris Langan</a><span>, a bouncer with an “IQ of 200,” are simply people who practice IQ tests and know them in and out, treating such IQ tests much the way Jeopardy contests treat the show—as a subject of obsession and study. And just like how being a good Jeopardy contestant has no connection to real genius, so too with those who score extremely high on IQ tests. Because what’s important to keep in mind is that</span></p><p><span>You can find all over the internet sites giving some form of this claim: “IQ is one of the most valid and reliable psychological constructs.” And this is true. . . </span><em>by the standards of psychology. </em><span>Don’t mistake this for being what a normal person would refer to as “reliable.” In the field of psychology, almost nothing is reliable. Effects regularly cannot be replicated, and those that can inevitably decrease in their effect size, often shrinking to the barely observable. Psychology </span><a href=\"https://www.psychologytoday.com/us/basics/replication-crisis\">struggles</a><span> as a discipline to achieve even close to the same tensile strength in its hypotheses as other scientific fields, like physics or biology. Yet, sometimes IQ is treated as if it rises, miraculously, above these problems.</span></p><p>It doesn’t. As IQ gets higher, it gets less definite. Rankings of Person A and B will swap places depending on what test they take. Meaning that IQ is “valid and reliable” at the level that psychologists care about, which is being able to get significant values for their p-values across large data sets. But here’s how actual scores look for individuals if they take different IQ tests:</p><p><span>J, who received a 101 on one test and an 86 on another, is either completely average or so dumb he almost cannot serve in the army (where the IQ cutoff is 83). L is either ready for her PhD at 124, or, alternatively, she and J are identical (102 vs. 101). There are a few people who are surprisingly stable, like F, but the majority vary by big point spreads. According to </span><a href=\"https://www.questarai.com/resources-docs/briefs/Assessment-Brief-Test-Reliability-Indicates-More-than-Just-Consistency.pdf\">some estimates</a><span>, the standard error of measurement of IQ tests is around seven points, meaning you should regularly expect things like 10-20 point spreads, just as we see here. (Broadly we can think of this error as being either across tests or upon re-taking the same test. The exact error might not even be a definable thing, but what’s relevant is that it can lead to large two-digit spreads, like J’s 15-point spread or L’s 22-point spread or B’s 20-point spread).</span></p><p><span>The situation is even worse for IQs of 140 plus. First, the number of tests that have higher ceilings and can reach stratospheric numbers is low. Which means the tests are not as well-established or researched, and instead are often ad hoc or not appropriately normed. The consequence is that the amount of uncertainty, the 20-point spreads, is for the normal range of scores, e.g., for scores below 125 or 130. Once you start climbing beyond that the variation in scores get larger and larger. It doubles. No, it quadruples! This effect has been known for a very long time, at least since </span><a href=\"https://en.wikipedia.org/wiki/IQ_classification#cite_note-TermanMerrill1937p44-106\">1937</a><span>. Here’s from the more recent “</span><em><a href=\"https://web.archive.org/web/20160315055952/https://faculty.education.uiowa.edu/docs/default-source/dlohman/ability-testing-and-talent-identification.pdf?sfvrsn=0\">Identification of Students for Gifted and Talented Services: Theory into Practice</a></em><span>:”</span></p><blockquote><p><span>The concerns associated with SEMs [standard errors of measurement] are actually substantially worse for scores at the extremes of the distribution, especially when scores approach the maximum possible on a test. . . when students answer most of the items correctly. In these cases, errors of measurement for scale scores will increase substantially at the extremes of the distribution. </span><strong>Commonly the SEM is from two to four times larger for very high scores than for scores near the mean.</strong></p></blockquote><p>Two to four times larger?! This means that spreads of 20-40 points should be the norm, and could get truly crazy beyond that. So we should expect Jack taking a high-ceiling IQ test and getting a 160, and then taking another high-ceiling IQ test and getting a 120. And there’s not an infinite battery of high-ceiling IQ tests we can throw at people to narrow this down (especially since small changes to the tests themselves will likely catapult us along some other axis of variance). This increasing incoherence of higher scores shows up in studies of the real-world impact of IQ, where the</p><p><span>This was precisely Nassim Taleb’s point when he wrote the anti-IQ screed “</span><a href=\"https://medium.com/incerto/iq-is-largely-a-pseudoscientific-swindle-f131c101ba39\">IQ is largely a pseudoscientific swindle</a><span>.” Taleb, never afraid to praise Taleb, recently </span><a href=\"https://twitter.com/nntaleb/status/1645735174410231809\">said</a><span> in a Tweet that “No piece in history has been more influential in fighting racism, eugenism, &amp; racial mandarinism” (these debates are long-standing and significantly predate Taleb’s essay). In the piece itself he argued, in traditional swing-for-the-fences fashion, that IQ tests are</span></p><blockquote><p><em>via negativa</em><span> not </span><em>via positiva</em><span>. Designed for learning disabilities. . . it ends up selecting for exam-takers, paper shufflers, obedient IYIs (intellectuals yet idiots), ill adapted for “real life”.</span></p></blockquote><p>This means that Taleb, instead of defending the motte (IQ at high levels doesn’t tell us about genius, in fact, high-IQ differentials don’t matter much if at all, and are immeasurable anyways) Taleb ended up defending the easily-attackable bailey (IQ tells us nothing!). The more tenable position is to be a believer in the first, and a disbeliever in the second. Yet most of Taleb’s critics took him at his word, and considered it a satisfying rebuttal that IQs above 100 scaled in correlation with anything at all—grades, income, whatever—no matter how weakly.</p><p><span>But given its known measurement variance, IQs mattering less and less at higher scales almost has to be true, since the variance alone injects huge amounts of noise into any study. From a statistical level it would be shocking to get really clear results differentiating any real-world factor between IQs of 130 vs. 150, simply because the error is so large, and the number of people even satisfying those conditions is so small (in fact, it’s quite likely that, due to variance and practice, the average Mensa member is </span><a href=\"https://cremieux.substack.com/p/mensa-the-above-average-iq-society\">far under</a><span> the actual IQ requirement). Consider a recent example: the debate over a big modern study published this January tracking 59,000 men.</span></p><div><figure><a href=\"https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F64a3237b-8d54-475d-b302-d45b50506517_936x1186.png\"><div><picture><source sizes=\"100vw\" srcset=\"https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F64a3237b-8d54-475d-b302-d45b50506517_936x1186.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F64a3237b-8d54-475d-b302-d45b50506517_936x1186.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F64a3237b-8d54-475d-b302-d45b50506517_936x1186.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F64a3237b-8d54-475d-b302-d45b50506517_936x1186.png 1456w\" type=\"image/webp\"><img srcset=\"https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F64a3237b-8d54-475d-b302-d45b50506517_936x1186.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F64a3237b-8d54-475d-b302-d45b50506517_936x1186.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F64a3237b-8d54-475d-b302-d45b50506517_936x1186.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F64a3237b-8d54-475d-b302-d45b50506517_936x1186.png 1456w\" src=\"https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F64a3237b-8d54-475d-b302-d45b50506517_936x1186.png\"></picture></div></a></figure></div><p><span>The problem with these debates, and leaning too much on one study, is that there is a huge literature on IQ, which means that people on either side of the debate can pull up a dozen studies showing whatever they want (there are a lot of fields like this). Yet, from what I can tell, the issue of test variance appears a barrier impossible to overcome. E.g., one might counter the above study showing that IQ ceases to matter for income with another, earlier study, that claims to answer “</span><a href=\"https://journals.sagepub.com/doi/abs/10.1177/1745691620964122?casa_token=hlwkSw6yKHAAAAAA%3A4ym66ghFVKNkqjdoUT7pVgOIPpqZiZAgoMp-HGxAsstJJu2mUjmUyU7EX36B4adkERIKao70blm8iQ&amp;journalCode=ppsa\">Can You Ever Be Too Smart for Your Own Good?</a><span>” in the negative. In that earlier study they correlated 214 life outcomes (things like educational achievement and income) to IQ, and find that</span></p><blockquote><p>Given these results, greater cognitive ability does not cease to remain beneficial for individuals with above average ability or with scores greater than IQ = 120.</p></blockquote><p>Well, that settles it, right? Nope. Because as usual, there’s a lot of motte and bailey switching here. What they actually find is that the difference in the hundreds of life outcomes gets tiny at the upper echelons of IQ.</p><blockquote><p>Finally, to check the possibility that only very high intelligence is detrimental, we tested for outcome differences between individuals within the top 10% and top 20% of ability scores. . . We performed a median split within each group (top 10% and top 20%) and compared outcome scores for individuals above or below the median using a simple t test or χ2 test of proportions. In only a minority of cases did we detect a significant difference (p &lt; .05) within the top 10% (20 out of 214 comparisons, 9%) or top 20% (48 out of 214 comparisons, 22%) of cognitive ability scores.</p></blockquote><p>So if we actually look at the numbers, there are statistically significant differences in only 48 out of 214 life outcomes in the top 20%, and only 20 out of 214 in the top 10%—and the effects are small too (despite starting from with a very large data set of ~50,000 individuals). Some of the effects are even negative! But this attenuating effect of IQ differentials correlating less and less to outcomes is papered over—instead, victory is declared that there is any detectable difference for IQs above 120 whatsoever.</p><p>If we put the increasingly absurd measurement error together with the lack of clear and replicable real-world difference, the simplest explanation when it comes to IQs of, e.g., 150, 160, 170, is that they simply aren’t real. At higher levels, Jack and Jill swap places endlessly, a game of musical chairs as they jump around 30-point spreads with no way to reliably reduce the variance. And what chair they happen to be sitting in for a particular test, ahead or behind, matters not at all to their life outcomes.</p><p>So if someone regularly talks about IQs significantly above 140 like these were actual measurable and reliable numbers that have a real-world effect, know that they are talking about a fantasy. And if they make claims that various historical figures possessed such numbers, then they’re talking unscientific nonsense. If they’re bragging about themselves, well. . . it’s like someone talking about their astrological sign. Stratospheric IQs are about as real as leprechauns, unicorns, mermaids—they’re fun to tell tales about, but the evidence for them being a repeatedly measurable phenomenon that matters in any meaningful sense of the word is zip, zero, zilch.</p><p><span>In fact, on re-reading it after originally planning to cite it for this essay, I was struck by Gould’s weak and judgy arguments in his </span><em>The Mismeasure of Man</em><span>, a book that supposedly takes down research on IQ. I don’t think that IQ is like measuring skull circumference, nor do I think just talking about IQ, or researching it, is bad, or evil, or inherently racist, or dumb, or whatever other accusation one can throw. I would definitely never say something like “IQ doesn’t matter at all.” I wouldn’t even say “IQ is unimportant.” I think it is important, in that it’s one of the only measurements we have that does an okay job at capturing intelligence, in that it’s not too bad at this when it comes to the center of the distribution, although it gets increasingly bad at it at the tails.</span></p><p><span>And, from a practical perspective, there is a sense in which I’m actually very pro-IQ tests! I recently bemoaned the quiet dropping of the SAT and GRE from college admissions, </span><a href=\"https://erikhoel.substack.com/p/i-owe-my-career-to-the-sat\">writing that</a><span>:</span></p><blockquote><p>This nation-wide change being officially enshrined this year troubles me in particular because it’s now no longer possible to get a middling high school GPA at a public school, get a top-notch SAT score, get to choose between a couple good colleges, and then have a successful career afterward. Which is how my life went. Of course, no one can really know the true counterfactuals, but it’s likely that the SAT is why I have a career as a scientist and author at all.</p></blockquote><p>But holding that opinion that doesn’t mean that I think really high IQ numbers are actually real, or that IQ is determinate past a certain point in judging “academic potential.”</p><p><span>A simple way of saying it: When I read Tolstoy, what I think is that the man was a genius. If he scored a 120 on an IQ test, that would reflect on IQ tests, not Tolstoy. This holds true in my personal experience as well. I’ve known a couple people in life who got perfect or near-perfect SAT scores and went on to places like Harvard and MIT. I would consider none of them geniuses. They just didn’t have </span><em>it</em><span>. On the other hand, I’ve also been lucky enough to be able to meet, and occasionally work alongside, people I would consider scientific geniuses. Yet never once did I feel that an IQ test would capture these people operating at the highest level of intellectual output (who I will avoid the embarrassment of name dropping). Many of these intellectual stars were not even quick-witted. Sure, all of them were smart, obviously so, and all of them would score above average, likely well above average, on an IQ test. But their individual rankings on those tests, when compared to each other, would mean absolutely nothing. It would just be dead information. Far more important was how they were deep creative thinkers with good instincts for what questions were fecund, coupled with an obsessive drive to pursue those questions. They had elegant minds, deep pools of expertise, and often voracious cultural knowledge outside their chosen discipline. They were people on fire with thought. So if you only did pretty good on the SAT, don’t worry too much. The evidence says you can still win the Nobel Prize.</span></p></div></article></div><div><h4>Discussion about this post</h4></div>",
      "author": "Seeds of Science",
      "description": "",
      "dateAdded": "2025-02-19T15:52:02.000Z",
      "media": {
        "images": [
          {
            "url": "https://substackcdn.com/image/fetch/f_auto,q_auto:best,fl_progressive:steep/https%3A%2F%2Ftheseedsofscience.substack.com%2Fapi%2Fv1%2Fpost_preview%2F157469292%2Ftwitter.jpg%3Fversion%3D4",
            "alt": "Your IQ isn't 160. No one's is.",
            "isHero": true
          }
        ],
        "videos": [
          {
            "type": "youtube",
            "id": "6WKsr4b_7NY",
            "url": "https://www.youtube.com/watch?v=6WKsr4b_7NY"
          }
        ]
      }
    },
    {
      "id": "31c107b7-3165-4793-8582-849908dd585f",
      "url": "https://www.wheresyoured.at/longcon/",
      "type": "article",
      "title": "The Generative AI Con",
      "content": "<article>\n      <p>It's been just over two years and two months since ChatGPT launched, and in that time we've seen Large Language Models (LLMs) blossom from a novel concept into one of the most craven cons of the 21st century — a cynical bubble inflated by OpenAI CEO Sam Altman built to sell into an economy run by people that have no concept of labor other than their desperation to exploit or replace it. </p><p>I realize that Large Language Models like GPT-4o — the model that powers ChatGPT and a bunch of other apps — <em>have use cases</em>, and I'm <em>fucking tired of having to write this sentence.</em> There are people that really like using Large Language Models for coding (<a href=\"https://www.axios.com/2024/06/13/genai-code-mistakes-copilot-gemini-chatgpt?ref=wheresyoured.at\"><u>even if the code isn't good</u></a> or<a href=\"https://www.zdnet.com/article/draft-theres-good-news-and-bad-news-with-ai-assisted-software-development/?ref=wheresyoured.at\"> <u>makes systems less secure and stable</u></a>) or get something out of Retrieval-Augmented Generation (RAG)-powered search, or like using one of the various AI companions or journal apps.&nbsp;</p><p>I get it. I get that there are people that use LLM-powered software, and I must be clear that <strong>anecdotal examples of some people using some software that they kind-of like is not evidence that generative AI is a sustainable or real industry at the trillion-dollar scale that many claim it is.</strong></p><p>I am <em>so very bored of having this conversation,</em> so I am now going to write out some counterpoints so that I don't have to say them again.</p><h3 id=\"ed-there-are-multiple-kinds-of-artificial-intelligence\"><strong>Ed, there are multiple kinds of artificial intelligence-</strong></h3><p><strong><em><u>I KNOW.</u></em></strong> Stop saying this to me like an Uno reverse! I'm talking about generative AI!</p><h3 id=\"well-ed-there-are-300-million-weekly-users-of-chatgpt-that-surely-proves-that-this-is-a-very-real-industry\"><strong>Well, Ed, there are</strong><a href=\"https://www.theverge.com/2024/12/4/24313097/chatgpt-300-million-weekly-users?ref=wheresyoured.at\"><strong> <u>300 million weekly users of ChatGPT</u></strong></a><strong>. That surely proves that this is a very real industry!</strong></h3><ol><li>Though I don't have an exact number, I'd estimate that there have been tens of thousands of articles about artificial intelligence written in the last two years that are specifically focused on the generative AI boom, which in turn guarantees that they'll mention ChatGPT.</li><li>The AI bubble means that effectively every single media outlet has been talking about artificial intelligence in the vaguest way, and there's really only been one \"product\" that they can try that \"is AI\" — and that product is ChatGPT.</li><li>Reporting on artificial intelligence,<a href=\"https://reutersinstitute.politics.ox.ac.uk/news/how-news-coverage-often-uncritical-helps-build-ai-hype?ref=wheresyoured.at\"> <u>according to the Reuters Institute for the Study of Journalism</u></a>, is led by industry sources, with coverage of artificial intelligence in the UK being summarized by one study as tending to “construct the expectation of a pseudo-artificial general intelligence: a collective of technologies capable of solving nearly any problem.\" Specifically, the Reuters Institute's Professor Rasmus Nielsen said that coverage \"often takes claims about what the technology can and can’t do, and might be able to do in the future, at face value in ways that contributes to the hype cycle.\"<ol><li>In short, most of the coverage you read on artificial intelligence is led by <strong>companies that benefit financially from you thinking artificial intelligence is important</strong> and <strong>by default all of this coverage mentions OpenAI or ChatGPT.</strong></li></ol></li><li>So...yeah, of course ChatGPT has that many users. When you have hundreds of different reporters constantly spitting out stories about how important something may or may not be, and when that thing is <em>available for free on a website</em>, it's going to get a bunch of people using it. This is predominantly the media's doing!</li><li><strong>But 300 million people is a lot!</strong><ol><li>It sure is! But it doesn't really prove anything other than that people are using the single-most-talked about product in the world. By comparison, billions of people use Facebook and Google. I don't care about this number!</li><li>User numbers alone tell you nothing about the sustainability or profitability of a business, or how those people use the product. It doesn’t delineate between daily users, and those who occasionally (and shallowly) flirt with an app or a website. It doesn’t say how <em>essential</em> a product is for that person.</li></ol></li></ol><h3 id=\"also-uhm-ed-its-early-days-for-chatgpt\"><strong>Also, uhm, Ed? It's early days for ChatGPT-</strong></h3><ol><li>Shut the fuck up! There isn't a single god damn startup in the history of anything — other than perhaps Facebook — that has had this level of coverage at such an early stage. Facebook also grew at a time when social media didn't really exist (at least, as a mainstream thing that virtually every demographic used) and thus the ability for something to \"go viral\" was a relatively new idea. By comparison, ChatGPT had the benefit of there being more media outlets, and Altman himself having spent a decade gladhandling the media<a href=\"https://www.wsj.com/tech/ai/openai-sam-altman-investments-004fc785?ref=wheresyoured.at\"> <u>through his startup investments</u></a> and crafting a real public persona.&nbsp;</li><li>The weekly users number is really weird. Did it really go from<a href=\"https://www.reuters.com/technology/artificial-intelligence/openai-says-chatgpts-weekly-users-have-grown-200-million-2024-08-29/?ref=wheresyoured.at\"> <u>200 million</u></a> to<a href=\"https://www.cnbc.com/2024/12/04/openais-active-user-count-soars-to-300-million-people-per-week.html?ref=wheresyoured.at\"> <u>300 million</u></a> users in the space of three months?<a href=\"https://www.reuters.com/technology/chatgpt-sets-record-fastest-growing-user-base-analyst-note-2023-02-01/?ref=wheresyoured.at\"> <u>It was at 100 million weekly users in <em>February 2023</em></u></a><em>. </em>You're telling me that OpenAI took, what, over a year to go from 100 million to 200 million, but it took <em>three months</em> (August 29 2024 to December 4 2024) to hit 300 million?<ol><li>I don't have any insider information to counter this, but I will ask — where was that growth from? OpenAI launched its o1 \"reasoning\" model (<a href=\"https://openai.com/index/introducing-openai-o1-preview/?ref=wheresyoured.at\"><u>the previews, at least</u></a>) on September 12 2024, but these were only available to ChatGPT Plus subscribers,<a href=\"https://www.searchenginejournal.com/openai-releases-chatgpt-o1-worlds-smartest-language-model/534597/?ref=wheresyoured.at\"> <u>with the \"full\" version released on December 5 2024</u></a>. You're telling me this company increased its free user base by <em>50%</em> in less than three months based on nothing other than the <em>availability of a product that wasn't available to free users?</em></li><li>This also doesn't make a ton of sense based on data provided to me by<a href=\"http://www.similarweb.com/?ref=wheresyoured.at\"> <u>Similarweb</u></a>, a digital market intelligence company. ChatGPT's monthly unique visitors were 212 million in September 2024, 233.1 million in October 2024, and 247.1 million in November 2024. I am not really sure how that translates to 300 million <em>weekly</em> users at all.<ol><li>Similarweb also provided me — albeit only for the last few weeks — data on ChatGPT.com's weekly traffic. For the period beginning January 21 2025, it only had 126.1 million weekly visitors. For the period beginning February 11 2025, it only had 136.7 million. Is OpenAI being honest about its user numbers? I've reached out for comment, but OpenAI has never, ever replied to me.<ol><li><strong>Sidenote: </strong>Yes, these are <strong><em>visitors</em></strong> versus <em><strong>users</strong></em>. However, one would assume users would be <em>lower</em> than visitors, because a visitor might not actually use the product. What gives?</li></ol></li><li>There could be users on their apps — but even then, I'm not really sure how you square this circle. An article from January 29 2025 says that<a href=\"https://techcrunch.com/2025/01/29/chatgpts-mobile-users-are-85-male-report-says/?ref=wheresyoured.at\"> <u>the iOS ChatGPT app has been downloaded 353 million times</u></a> <em>in total</em>. Based on even the most optimistic numbers, are you telling me that ChatGPT has over 100 million <em>mobile only</em> users a week? And no, it isn’t Apple Intelligence.<a href=\"https://www.cnbc.com/2024/12/11/apple-launches-its-chatgpt-integration-with-siri.html?ref=wheresyoured.at#:~:text=Apple%20Intelligence%20is%20the%20company's,of%20Apple%20Intelligence%20in%20October.\"><u> Cupertino didn’t launch that integration until December 11 2024.</u></a>&nbsp;</li><li>Here's another question: why doesn't OpenAI reveal <em>monthly </em>active users? Wouldn't that number be higher? After all, a monthly active user is one that uses an app <em>even once</em> over a given month! Anyway, I hypothesize that the reason is probably that<a href=\"https://www.theinformation.com/articles/openai-coo-says-chatgpt-passed-11-million-paying-subscribers?rc=kz8jh3&amp;ref=wheresyoured.at\"> <u>in September 2024 it came out that OpenAI had 11 million monthly paying subscribers</u></a>, and though ChatGPT likely has quite a few more people that use it once a month, admitting to that number would mean that <strong>we're able to see how absolutely abominable its conversion to paying users is. </strong>300 million monthly active users would mean a conversion rate of less than 4%, which is pretty piss-poor,<a href=\"https://www.wheresyoured.at/oai-business/#:~:text=ChatGPT%20Plus%2C%20Teams%2C%20and%20Enterprise%20%E2%80%94%2073%25%20of%20revenue%20(approximately%20%242.7%20billion).\"> <u>especially as subscription revenue for ChatGPT Plus (and other monthly subscriptions) makes up the majority of OpenAI's revenue</u></a>.</li></ol></li><li>Hey, wait a second. Are there any other generative AI products that reveal their users? Anthropic doesn't.<a href=\"https://searchengineland.com/perplexity-plan-sell-ads-438904?ref=wheresyoured.at\"> <u>AI-powered search product Perplexity claims to have 15 million monthly active users</u></a>. These aren't big numbers! They suggest these products aren't popular!<a href=\"https://www.wsj.com/tech/ai/google-gemini-2025-chatgpt-openai-b6eb595d?ref=wheresyoured.at\"> <u>Google allegedly wants 500 million users of its Gemini chatbot by the end of the year</u></a>, but there isn't any information about how many it’s at right now.<ol><li>Similarweb data states that google.gemini.com had 47.3 million unique monthly visitors in January 2025, copilot.microsoft.com had 15.6 million, Perplexity.ai had 10.6 million, and claude.ai had 8.2 million. These aren't great numbers! These numbers suggest that these products aren't very popular at all!</li><li>The combined unique monthly visitors in January 2025 to ChatGPT.com (246m), DeepSeek.com (79.9m), Gemini.Google.com (47.3m), Copilot.microsoft.com (15.6m), Perplexity.ai (10.6m), character.ai (8.4m), claude.ai (8.2m) and notebookLM.google.com (7.4m) was 423.4 million - or an astonishing 97.5 million if you remove ChatGPT and DeepSeek.&nbsp;<ol><li>For context, the New York Times <a href=\"https://nytco-assets.nytimes.com/2024/03/2023-Annual-Report_WR_-Final.pdf?ref=wheresyoured.at\"><u>said in their 2023 annual report that they received 131 million unique monthly visitors globally</u></a>, and <a href=\"https://cnnpressroom.blogs.cnn.com/cnn-fact-sheet/?ref=wheresyoured.at#:~:text=CNN's%20coverage%20is%20supplemented%20and,unique%20visitors%20globally%20each%20month.\"><u>CNN says they have more than 151 million unique monthly visitors</u></a>.&nbsp;</li></ol></li></ol></li></ol></li><li><strong>This isn't the early days of <em>shit.</em></strong> The<a href=\"https://arxiv.org/abs/1706.03762?ref=wheresyoured.at\"> <u>Attention Is All You Need paper</u></a> that started the whole transformer-based architecture movement was published in June 2017. We're over two years in, hyperscalers have<a href=\"https://www.bloomberg.com/professional/insights/technology/big-tech-2025-capex-may-hit-200-billion-as-gen-ai-demand-booms/?ref=wheresyoured.at\"> <u>sunk over 200 billion dollars in capital expenditures into generative AI</u></a>,<a href=\"https://www.crowdfundinsider.com/2024/10/230839-ai-startups-have-acquired-1-in-3-vc-dollars-research-study/?ref=wheresyoured.at\"> <u>AI startups took up a third of all venture capital investment in 2024</u></a>, and almost every single talented artificial intelligence expert is laser-focused on Large Language Models. <strong><em>And even then, we still don't have a killer app! There is no product that everybody <u>loves</u>, and there is no iPhone moment!</em></strong></li></ol><h3 id=\"well-ed-i-think-chatgpt-is-the-iphone-moment-for-generative-ai-its-the-biggest-software-launch-of-all-time\"><strong>Well Ed, I think ChatGPT is the iPhone moment for generative AI, it's the biggest software launch of all time-</strong></h3><ol><li>Didn't we just talk about this? Fine, fine. Let's get specific. The iPhone fundamentally redefined what a cellphone and a portable computer could be, as did the iPad, creating entirely new consumer and business use cases almost immediately. Cloud computing allowed us to run distinct applications in the cloud, which totally redefined how software was developed and deployed, creating both entirely new use cases for software (as the compute requirements moved from the customer to the provider), and<a href=\"https://aag-it.com/the-latest-cloud-computing-statistics/?ref=wheresyoured.at#:~:text=Operator%20and%20vendor%20revenues%20for,%24195%20billion%20of%20total%20revenues.\"> <u>an entirely new cloud computing <em>industry</em> that makes hundreds of billions of dollars a year</u></a>.</li><li>So, what exactly has generative AI actually done? Where are the products? No, really, where are they? What's the product you use every day, or week, that uses generative AI, that truly changes your life? If generative AI disappeared tomorrow — assuming you are not somebody who actively builds using it — would your life materially change?</li><li>The answer is \"not that much.\" Putting aside the hype, bluster and ungodly amounts of money, I can find no evidence that any of these apps are making anyone any real money. Microsoft claims to have hit \"<a href=\"https://www.geekwire.com/2025/microsoft-earnings-2/?ref=wheresyoured.at\"><u>$13 billion in annual run rate in revenue from its artificial intelligence products and services</u></a>,\" which amounts to just over a billion a month, or $3.25 billion a quarter.<ol><li>This is not profit. It's revenue.</li><li><a href=\"https://www.microsoft.com/en-us/investor/earnings/fy-2025-q1/press-release-webcast?ref=wheresyoured.at\"><u>There is no \"artificial intelligence\" part of Microsoft's revenue or earnings</u></a>. This is literally Microsoft taking anything with \"AI\" on it and saying \"we made money!\"</li><li>$3.25 billion a quarter is absolutely pathetic. In its most recent quarter, Microsoft<a href=\"https://www.cnbc.com/2025/01/29/microsoft-msft-q2-earnings-report-2025.html?ref=wheresyoured.at\"> <u>made $69.63 billion</u></a>, with its Intelligent Cloud segment (which includes things like their Azure cloud computing solutions)<a href=\"https://www.cnbc.com/2025/01/29/microsoft-msft-q2-earnings-report-2025.html?ref=wheresyoured.at\"> <u>making $25.54 billion in revenue</u></a>, and spent $15.80 billion in capital expenditures <em>excluding non-specific finance leases</em>.</li><li>In the last year, Microsoft has spent<a href=\"https://finbox.com/NASDAQGS:MSFT/explorer/capex/?ref=wheresyoured.at#:~:text=Microsoft's%20operated%20at%20median%20capital,December%202024%20at%2055.552%20billion.\"> <u>over $55 billion capital expenditures to maybe</u></a> (to be clear, the $13 billion in run rate <em>is a projection using current financial performance to predict future revenue) </em>make $13 billion. This is not a huge industry! These are not good numbers, especially considering the massive expenses!</li></ol></li></ol><h3 id=\"theyll-work-it-out\"><strong>They'll Work It Out!</strong></h3><ol><li>When? No, really, when?<ol><li>OpenAI burned more than $5 billion last year.</li><li>According to The Information,<a href=\"https://www.theinformation.com/articles/anthropic-projects-soaring-growth-to-34-5-billion-in-2027-revenue?rc=kz8jh3&amp;ref=wheresyoured.at\"> <u>Anthropic burned <em>$5.6 billion</em></u></a><em>.</em> That may very likely mean Anthropic burned <em><strong>more money than OpenAI somehow last year!</strong> </em>These companies are absolutely atrocious at business! The reason I’m not certain is that in the past The Information has been a touch inconsistent with how it evaluates \"costs,\" in that I’ve seen it claim that OpenAI \"burned just $340 million in the first half of 2024,\"<a href=\"https://www.theinformation.com/articles/openai-projections-imply-losses-tripling-to-14-billion-in-2026?rc=kz8jh3&amp;ref=wheresyoured.at\"> <u>a number that they pulled from a piece from last year</u></a> followed by the statement that \"[OpenAI's] losses \"are steep due to the impact of major expenses, such as stock compensation and computing costs, that don't flow through its cash statement.\" To be clear, OpenAI burned approximately $5 billion on compute alone. So yeah, OpenAI “burned only $340 million last year” as long as you don’t consider billions of other costs for some reason. Great stuff! It isn’t obvious how The Information is evaluating Anthropic’s burn versus OpenAI’s, and I’ve reached out to Jon Victor over there to get some clarity. I want to be clear that I very much appreciate, value and recommend The Information’s journalism, but I do not accept the idea of arbitrarily leaving out costs. This isn’t real business! Sorry!&nbsp;</li><li>None of these companies are profitable, and despite repeated claims that \"the cost of inference is coming down\" (the thing that happens when you prompt the model to do something) it doesn't appear to be helping them.<a href=\"https://www.wheresyoured.at/deep-impact/\"> <u>In the weeks following the release of the super-efficient DeepSeek models</u></a> I kind of expected them to start talking about efficiency. They never addressed it other than OpenAI, which said that<a href=\"https://www.wheresyoured.at/what-were-fighting-for/\"> <u>DeepSeek would cause it to maintain less of a lead</u></a>. Great stuff!</li></ol></li></ol><h3 id=\"what-are-we-doing-here\"><strong>What Are We <em>Doing</em> Here?</strong></h3><p>OpenAI and Anthropic are both burning billions of dollars a year, and do not appear to have found a way to stop doing so. The only \"proof\" that they are going to reverse this trend is The Information saying that \"<a href=\"https://www.theinformation.com/articles/anthropic-projects-soaring-growth-to-34-5-billion-in-2027-revenue?rc=kz8jh3&amp;ref=wheresyoured.at\"><u>Anthropic's management expects the company to stop burning cash in 2027</u></a>.\"</p><blockquote><strong>Sidebar: </strong>Hey, what is it with Dario Amodei of Anthropic and the year 2027?<a href=\"https://arstechnica.com/ai/2025/01/anthropic-chief-says-ai-could-surpass-almost-all-humans-at-almost-everything-shortly-after-2027/?ref=wheresyoured.at\"> <u>He said (made up) that \"AI could surpass almost all humans at almost everything\" \"shortly after 2027\" in January</u></a>. He said<a href=\"https://www.anthropic.com/news/paris-ai-summit?ref=wheresyoured.at\"> <u>in one of his stupid and boring blogs</u></a> that \"possibly by 2026 or 2027 (and almost certainly no later than 2030)\" that \"capabilities of AI systems will be best thought of as akin to an entirely new state populated by highly intelligent people appearing on the global stage—a “country of geniuses in a datacenter.\" This man is full of shit! Hey, tech media people reading this — your readers hate this shit! Stop printing it! Stop it!</blockquote><p>While one could say \"the costs will come down,\" and that appears to be what The Information is claiming, suggesting that \"Anthropic said it would reduce its burn rate by \"nearly half\" in 2025, the actual details are thin on the ground, and there’s no probing of whether that’s even feasible without radically changing its models. Huh? How? Anthropic’s burn increased every single year! So has OpenAI's!</p><p>The Information — who I do generally, and genuinely, respect — ran an astonishingly optimistic piece about Anthropic <a href=\"https://www.theinformation.com/articles/anthropic-projects-soaring-growth-to-34-5-billion-in-2027-revenue?rc=kz8jh3&amp;ref=wheresyoured.at\"><u>estimating that it'd make $34.5 billion in revenue in 2027</u></a> (there's that year again!), the very same year it’d stop burning cash. Its estimates are based on the premise that \"leaders expected API revenue to hit $20 billion in 2027,\" meaning people plugging Anthropic's models into their own products. This is laughable on many levels, chief of which is that OpenAI, which made around twice as much revenue as Anthropic did in 2024,<a href=\"https://www.wheresyoured.at/oai-business/#:~:text=Licensing%20Access%20To%20Models%20And%20Services%20%E2%80%94%2027%25%20of%20revenue%20(approximately%20%241%20billion).\"> <u>barely made a billion dollars from API calls in the same year</u></a>.</p><p>It's here where I'm going to choose to scream.</p><p>Anthropic, according to The Information, generated <strong><em>$908 million in revenue in 2024,</em></strong> and has <u>projected</u> that it will make $2.2 billion in revenue in 2025, and its \"base case\" — which The Information says would be \"the likeliest outcome (???) — is that it will make $12 billion in revenue in 2027.&nbsp;</p><p>This is what happens during bubbles! Assets are over-valued based on a combination of vibes and hysteria!&nbsp;</p><p>Dario Amodei — much like Sam Altman — is a liar, a crook, a carnival barker and a charlatan, and the things he promises are equal parts ridiculous and offensive. The Information (which needs to do better work actually critiquing these people) justified Amodei and Anthropic's obscene and fantastical revenue targets by<a href=\"https://www.anthropic.com/news/paris-ai-summit?ref=wheresyoured.at\"> <em><u>citing Amodei's blog</u></em></a><strong>, </strong>which at no point explains what a \"country of geniuses in a datacenter\" actually means or what the product might be or what he's going to do to increase revenue by <em>more than thirty billion dollars a year</em> by 2027.</p><p>But wait, The Information says it got a little more specific!</p><blockquote>Anthropic says its technology could transform office roles such as generating or reviewing legal paperwork and automating software engineering. It cited code repository GitLab and legal search firm LexisNexis as examples of customers. Up-and-coming startups such as Anysphere, which develops the Cursor coding assistant for programmers, are also major buyers of Claude software.</blockquote><p>So, just to be abundantly clear, it appears Anthropic's big plan is to \"sell people more software to some people, maybe.\"</p><p><a href=\"https://www.wsj.com/tech/ai/ai-startup-anthropic-raising-funding-valuing-it-at-60-billion-19d0605a?ref=wheresyoured.at\"><u>Anthropic is currently raising $2 billion at a $60 billion valuation</u></a> primarily based off of this trumped-up marketing nonsense. Why are we humoring these oafs?</p><h3 id=\"what-these-oafs-are-actually-doing\"><strong>What These Oafs Are Actually Doing</strong></h3><p>When you put aside the hype and anecdotes, generative AI has languished in the same place, even in my kindest estimations, for several months, though it's really been years. The one \"big thing\" that they've been able to do is to use \"reasoning\" to make the Large Language Models \"think\" (they do not have consciousness, they are not \"thinking,\" this just means using more tokens to answer a particular question and having multiple models check the work), which mostly results in them being a bit more accurate when generating an answer, but at the expense of speed and cost.</p><p>This became a little less exciting a month ago when<a href=\"https://www.wheresyoured.at/deep-impact/\"> <u>DeepSeek released its open source \"r1\" model which performed similarly to reasoning products from companies like Google and OpenAI</u></a>, and while some argue it \"built the model to game benchmarks,\" that is quite literally what every single model developer does. Nevertheless, the idea of \"reasoning\" being the \"killer app\" — despite the fact that nobody can really explain why it's such a big deal — is now quite dead.</p><p>As a result, the model companies are kind of flailing. In a recent post on Twitter, Sam Altman gave an \"<a href=\"https://x.com/sama/status/1889755723078443244?ref=wheresyoured.at\"><u>updated roadmap for GPT 4.5 and GPT-5</u></a>\" where he described how OpenAI would be \"simplifying\" its product offerings, saying that GPT-4.5 would be OpenAI's \"last non-chain-of-thought model,\" and that GPT-5 would be \"a system that integrates a lot of our technology,\" including o3, OpenAI's \"powerful\" and \"<a href=\"https://futurism.com/the-byte/openai-o3-cost-per-query?ref=wheresyoured.at\"><u>very expensive</u></a>\" reasoning model, which it...would also no longer release as a standalone model.</p><p>To break this down, Altman is describing his next model — GPT 4.5 — as launching in some indeterminate timeframe and doing something probably quite similar to the current GPT 4o model. In the case of GPT-5, it would appear that Altman is saying that it won't be a model at all, but some sort of rat king of different mediocre products, including o3, a product that he would no longer be letting you use.</p><p>I guess that's the future of this company, right? OpenAI will release models and uh, well. Uhh.</p><p><em>Uhhhhhhh.</em></p><p>Wait! Wait! OpenAI released a new product! It's called Deep Research, which lets you ask ChatGPT to generate a report by browsing the web. This is almost a cool idea. I sure hope that it doesn't make glaring mistakes and cost a shit-ton of money!</p><p>Anyway, <a href=\"https://www.platformer.news/chatgpt-deep-research-hands-on/?ref=wheresyoured.at\"><u>let's go to Casey Newton at Platformer for the review</u></a>:</p><blockquote>Generally speaking, the more you already know about something, the more useful I think deep research is. This may be somewhat counterintuitive; perhaps you expected that an AI agent would be well suited to getting you up to speed on an important topic that just landed on your lap at work, for example.&nbsp; In my early tests, the reverse felt true. Deep research excels for drilling deep into subjects you already have some expertise in, letting you probe for specific pieces of information, types of analysis, or ideas that are new to you.<p>It’s possible that you can make this work better than I did. (I think all of us will get better at prompting these models over time, and presumably the product will improve over time as well.)</p></blockquote><p>Personally, when I ask someone to do research on something, I don't know what the answers will be and rely on the researcher to explain stuff through a process called \"research.\" The idea of going into something knowing about it well enough to <em><strong>make sure the researcher didn't fuck something up</strong></em> is kind of counter to the point of <em>research itself.</em></p><p>Also: \"I think all of us will get better at prompting-\" Casey, we're paying them! We're paying them for them to do stuff for us!</p><p>Nevertheless, I did go and look up one of Casey's examples,<a href=\"https://chatgpt.com/share/67a15df0-d2a8-8003-a8df-f01c5ce82083?ref=platformer.news\"> <u>specifically one about how the Fediverse could benefit publishers</u></a>.</p><p><strong>Let's do some research!</strong></p><blockquote>Despite Newton's fawning praise, the citations in this \"deep research\" are flimsy at best.<a href=\"https://www.twipemobile.com/what-is-the-fediverse-a-guide-for-publishers-and-the-uninitiated/?ref=wheresyoured.at#:~:text=Interoperability%3A%20Because%20ActivityPub%20enables%20different,who%20uses%20a%20different%20server\"> <u>The first (and second) citation</u></a>s are from an SEO-bait article about the fediverse from a \"news solutions\" company called \"Twipe\" and is used to define \"broad cross-platform reach.\" The next one is<a href=\"https://digiday.com/media/why-publishers-are-preparing-to-federate-their-sites/?ref=wheresyoured.at#:~:text=At%20least%20two%20digital%20media,driving%20readers%20to%20publishers%E2%80%99%20sites\"> <u>from reputable digital advertising outlet Digiday</u></a>, but it's used to cite how sites like 404 Media and The Verge are \"actively exploring the Fediverse to take more control over their referral traffic and onsite audience engagement,\" which is plagiarised ad-verbatim from the Digiday article.<p>After that, the next three citations are <em>posts from Hackernews, a web forum started by yCombinator </em>(</p><a href=\"https://news.ycombinator.com/item?id=34916396&amp;ref=wheresyoured.at#:~:text=Mastodon,now%20a%20pretty%20lonely%20place\"><u>here's an example</u></a>). How is this \"deep research\" exactly?<p>In fact, this thing isn't well-researched at all. Across the following paragraphs, Deep Research cites the same Digiday article <em>eight times</em>, before going back to citing the same Twipe article again. It also, hilariously, says that federated posts \"can simultaneously publish to [a] website and as a toot on federated platforms like Mastodon and Threads,\"</p><a href=\"https://gizmodo.com/mastodon-toot-retired-twitter-tweet-equivalent-1849786221?ref=wheresyoured.at\"> <u>a term that Mastodon retired two years ago</u></a>.<p>The next two citations are about</p><a href=\"https://blog.medium.com/medium-embraces-mastodon-19dcb873eb11?ref=wheresyoured.at#:~:text=air%E2%80%A6%20blog,a%20home%20in%20the%20fediverse\"> <u>Medium's embrace of Mastodon</u></a>, followed by yet another citation of the Digiday article. Following that, Deep Research cites two different Reddit posts, a company called<a href=\"https://community.interledger.org/jeremiahlee/interledger-joins-the-fediverse-30fi?ref=wheresyoured.at#:~:text=Some%20people%20might%20worry%20that,over%20predominantly%20exclusive%20paid%20access\"> <u>Interleger moving to the Fediverse</u></a>, which the report cites several more times, along with yet another forum post, <em>the very same Twipe post several more times</em>, and<a href=\"https://docs.bsky.app/docs/advanced-guides/atproto?ref=wheresyoured.at#:~:text=This%20distinction%20is%20intended%20to,choice\"> <u>then the support documentation for social network Bluesky several more times</u></a>.<p>I won't go through more of the research paper citation by citation, but you'll be shocked to hear it mostly just cites Twipe and Hackernews and Reddit.</p><p>For now, Deep Research is only available on ChatGPT Pro, OpenAI's</p><a href=\"https://www.theregister.com/2025/01/06/altman_gpt_profits/?ref=wheresyoured.at\"> <u>somehow-unprofitable</u></a> $200-a-month subscription,<a href=\"https://x.com/sama/status/1886220053219069995?ref=wheresyoured.at\"> <u>though it's apparently coming to ChatGPT Plus in a limited capacity</u></a>.<p>Not impressed? Well what if I told you it was</p><a href=\"https://x.com/sama/status/1886220051092512979?ref=wheresyoured.at\"> <u>very compute-intensive and expensive</u></a>? Oh, one other detail — the entire thing’s on the very <em>edge </em>of comprehensible. <p>Here’s a bit under funding models:</p><p><em><strong>\"Memberships and Donations:</strong> A common monetization approach in the Fediverse (and across the open web) is voluntary support from the audience.\"</em></p><p>Nobody talks like this! This isn’t how human beings sound! I don’t like reading it! I don’t know how else to say this — there is something deeply unpleasant about how Deep Research reads! It’s uncanny valley, if the denizens of said valley were a bit dense and lazy. It’s quintessential LLM copy — soulless and almost, but <em>not quite</em>, right.</p><p>Ewww.</p></blockquote><p>So there you have it folks. OpenAI's next big thing is the ability to generate a report that you would likely not be able to use in any meaningful way anywhere, because while it can browse the web and find things and write a report, it sources things based on what it thinks can confirm its arguments rather than making sure the source material is valid or respectable. This system may have worked if the internet wasn't entirely poisoned by companies trying to get the highest ranking in Google, and if Google had any interest in making sure its results were high quality,<a href=\"https://www.wheresyoured.at/the-men-who-killed-google/\"> <u>which it does not</u></a>.</p><p>I'm sorry, I know I sound like a hater, and perhaps I am, but this shit doesn't impress me even a little. Wow, you created a superficially-impressive research project that's really long and that cites a bunch of shit it found online that it made little attempt to verify? And said report took a while to generate, can only be produced if you pay OpenAI $200 each month, and it cost a bunch of money in compute to make?</p><p>Deep Research has the same problem as every other generative AI product. These models don't <em>know</em> anything, and thus everything they do — even \"reading\" and \"browsing\" the web — is limited by their training data and probabilistic models that can say \"this is an article about a subject\" and posit their <em>relevance</em>, but not truly understand their contents. Deep Research repeatedly citing SEO-bait as a primary source proves that these models, even when grinding their gears as hard as humanely possible, are exceedingly mediocre, deeply untrustworthy, and ultimately useless.</p><p>Furthermore, nothing about this product moves OpenAI toward profitability. In fact, I think they're doing the opposite. Deep Research uses OpenAI's o3 model<a href=\"https://futurism.com/the-byte/openai-o3-cost-per-query?ref=wheresyoured.at\"> <u>which can cost as much as $1,000 a query</u></a>, and while I imagine these prompts aren't <em>that </em>expensive, they are still significantly more so than a regular query from ChatGPT.</p><p>The whole point of hiring a researcher is that you can rely on their research, that they're doing work for you that would otherwise take you hours. Deep Research is the AI slop of academia — low-quality research-slop built for people that don't really care about quality or substance, and it’s not immediately obvious who it’s for.&nbsp;</p><p>Surely, if you’re engaged enough to spend $200 on an OpenAI subscription and are aware of Deep Research, you probably know what SEO bait is, and can distinguish between low-quality and high-quality content. If you were presented with a document with such low-quality, repetitive citations, you’d shred it — and, if created by an intern, you’d shred them too. Or, at the very least, give them some stern words of guidance.&nbsp;</p><p>Let me put this in very blunt terms: we are more than two years into the generative AI boom and OpenAI's biggest, sexiest products are Deep Research — a product that dares to ask \"what if you were able to spend a lot of compute to get a poorly-cited research paper,\" and <a href=\"https://www.wheresyoured.at/deep-impact/#:~:text=OpenAI%20is%20as,these%20tasks%20yourself.%22\"><u>Operator, a compute-intensive application that rarely completes a task in minutes that would otherwise have taken you seconds</u></a>.</p><p>As an aside, SoftBank, the perennial money-losers that backed WeWork and WireCard and<a href=\"https://techcrunch.com/2023/05/11/softbank-vision-fund-loses-32-billion-in-a-year-on-startups-valuation-cut/?ref=wheresyoured.at\"> <u>lost more than $30 billion in the last few years</u></a>,<a href=\"https://www.wsj.com/tech/softbank-in-talks-to-invest-up-to-25-billion-in-openai-03d653fc?mod=article_inline&amp;ref=wheresyoured.at\"> <u>are trying to invest up to $25 billion in OpenAI</u></a>.</p><h3 id=\"i-feel-like-im-going-insane\"><strong>I Feel Like I'm Going Insane</strong></h3><p>Everywhere you look, the media is telling you that OpenAI and their ilk are the future, that they're building \"advanced artificial intelligence\" that can take \"human-like actions,\" but when you look at any of this shit for more than two seconds it's abundantly clear that it absolutely isn't and absolutely can't.</p><p>Despite the hype, the marketing, the tens of thousands of media articles, the trillions of dollars in market capitalization, none of this feels real, or at least real enough to sustain this miserable, specious bubble. People like Marc Benioff claiming that \"<a href=\"https://www.cnn.com/2025/01/23/business/davos-marc-benioff-salesforce-ai-prediction-intl/index.html?ref=wheresyoured.at\"><u>today's CEOs are the last to manage all-human workforces</u></a>\" are doing so to pump up their stocks rather than build anything approaching a real product. These men are constantly lying as a means of sustaining hype, never actually discussing <strong><em>the products they sell in the year 2025</em></strong>, because then they'd have to say \"what if a chatbot, a thing you already have, was more expensive?\"</p><p>The tech industry — and part of our economy — is accelerating at speed into a brick wall, driven by people like Sam Altman, Dario Amodei, Marc Benioff, and Larry Ellison, all men that are incentivized to have you value their companies based on something <em>other</em> than what their businesses actually sell.&nbsp;</p><p>We are in the midst of a group delusion — a consequence of an economy ruled by people that do not participate in labor of any kind outside of sending and receiving emails and going to lunches that last several hours — where the people with the money do not understand or care about human beings.&nbsp;</p><p>Their narrative is built on a mixture of hysteria, hype, and deeply cynical hope in the hearts of men that dream of automating away jobs that they would never, ever do themselves. Altman uses his digital baba yaga as a means to stoke the hearts of weak-handed and weak-hearted narcissists that would sooner shoot a man dead than lose a dollar, even if it means making their product that much worse. CEOs have the easiest jobs in the world, and no job is easier than Satya Nadella waving to the Microsoft 365 staff and saying “make them put AI in it, pronto” and telling Microsoft CFO Amy Hood that “we must make sure that Bing has generative AI” before jetting off to Davos to <a href=\"https://www.youtube.com/watch?v=rUO7H7OtW3E&amp;ref=wheresyoured.at\"><u>yell that he intends to burn more money than ever on GPUs</u></a>.</p><p>Sam Altman believes you are stupid. He believes you are a moron that will slurp up whatever slop he gives you. Deep Research and Operator are both half-products that barely brush against the fabric of their intended purposes, and yet the media screams and applauds him like he's a gifted child that just successfully tied his shoes.</p><p>I know, I know, I'm a hater, I'm a pessimist, a cynic, but I need you to fucking listen to me: everything I am describing is unfathomably dangerous,<a href=\"https://slate.com/technology/2025/02/ed-zitron-interview-big-tech-ai-criticism.html?ref=wheresyoured.at#:~:text=With%20ChatGPT%20and,really%20matters%20here%3F\"> <u>even if you put aside the environmental and financial costs</u></a>.</p><p>Let me ask you a question: what's more likely?</p><p>That OpenAI, a company that has only ever burned money, that appears completely incapable of making a truly usable, meaningful product, somehow makes its products profitable, and then somehow creates a truly autonomous artificial intelligence?</p><p>Or that OpenAI, a company that has consistently burned billions of dollars, that has never shown any sign of making a profit, that has in two years released a selection of increasingly-questionable and obtuse products, actually runs out of money?</p><p>How does this industry actually continue? Do OpenAI and Anthropic continue to raise tens of billions of dollars every six months until they work this out?<a href=\"https://www.datacenterdynamics.com/en/news/morgan-stanley-hyperscaler-capex-to-reach-300bn-in-2025/?ref=wheresyoured.at\"> <u>Do the hyperscalers keep spending hundreds of billions of dollars in capital expenditures for little measurable return</u></a>?</p><p>And fundamentally, when will everybody start accepting that the things that AI companies are saying have absolutely nothing to do with reality? When will the media stop treating every single expensive, stupid, irksome, quasi-useless new product is magical, and start asking these people to show us the fucking <em>future</em> already?</p><p>Generative AI is a financial, ecological and social time bomb, and I believe that it's fundamentally damaging the relationship between the tech industry and society, while also shining a glaring, blinding light on the disconnection between the powerful and regular people. The fact that Sam Altman can ship such mediocre software and get more coverage and attention than every meaningful scientific breakthrough of the last five years combined is a sign that our society is sick, our media is broken, and that the tech industry thinks we're all fucking morons.</p><p>This entire bubble has been inflated by hype, and by outright lies by people like Sam Altman and Dario Amodei, their lies perpetuated by a tech media that's incapable of writing down what's happening in front of their faces. Altman and Amodei are raising billions and burning our planet based on the idea that their mediocre cloud software products will somehow wake up and automate our entire lives.</p><p>The truth is that generative AI is as mediocre as it is destructive, and those pushing it as \"the future\" that \"will change everything\" are showing how much contempt they have for the average person. They believe that they can shovel shit into our mouths and tell us it's prime rib, that these half-assed products will change the world and that as a result they need billions of dollars and to<a href=\"https://www.datacenterdynamics.com/en/news/ai-data-centers-causing-distortions-in-us-power-grid-bloomberg/?ref=wheresyoured.at\"> <u>damage our power grid</u></a>.</p><p>I know this has been a rant-filled newsletter, but I'm so tired of being told to be excited about this warmed-up dogshit. I'm tired of reading stories about Sam Altman<a href=\"https://www.techradar.com/computing/artificial-intelligence/sam-altman-says-ai-is-progressing-faster-than-moores-law-as-he-predicts-agi-is-coming-into-view-and-its-leaving-me-worried-about-the-future?ref=wheresyoured.at\"> <u>perpetually saying that we're a year away from \"everything changing</u></a>\" that exist only to perpetuate the myth that Silicon Valley gives a shit about solving anyone's problems other than<a href=\"https://www.wheresyoured.at/rotcombubble/\"> <u>finding new growth markets for the tech industry</u></a>.&nbsp;</p><p>I refuse to sit here and pretend that any of this matters. OpenAI and Anthropic are not innovators, and are antithetical to the spirit of Silicon Valley. They are management consultants dressed as founders, cynical con artists raising money for products that will never exist while peddling software that destroys our planet and diverts attention and capital away from things that might solve real problems.</p><p>I'm tired of the delusion. I'm tired of being forced to take these men seriously. I'm tired of being told by the media and investors that these men are building the future when the only things they build are mediocre and expensive. There is no joy here, no mystery, no magic, no problems solved, no lives saved, and very few lives changed other than new people added to Forbes' Midas list.</p><p>None of this is powerful, or impressive, other than in how big a con it’s become. Look at the products and the actual outputs and tell me — does any of this actually feel like the future? Isn’t it kind of weird that the big, scary threats they’ve made about how AI will take our jobs never seem to translate to an actual product? Isn’t it strange that despite all of their money and power they’re yet to make anything truly useful?&nbsp;</p><p>My heart darkens, albeit briefly, when I think of how cynical all of this is. Corporations building products that don't really do much that are being sold on the idea that one day they might, peddled by reporters that want to believe their narratives — and in some cases actively champion them. The damage will be tens of thousands of people fired, long-term environmental and infrastructural chaos, and a profound depression in Silicon Valley that I believe will dwarf the dot-com bust.</p><p>And when this all falls apart — and I believe it will — there will be a very public reckoning for the tech industry.</p>\n    </article>",
      "author": "",
      "description": "",
      "dateAdded": "2025-02-17T18:51:09.000Z",
      "media": {
        "images": [
          {
            "url": "https://www.wheresyoured.at/content/images/2024/01/wyea--1.jpeg",
            "alt": "The Generative AI Con",
            "isHero": true
          }
        ],
        "videos": [
          {
            "type": "youtube",
            "id": "rUO7H7OtW3E",
            "url": "https://www.youtube.com/watch?v=rUO7H7OtW3E"
          }
        ]
      }
    },
    {
      "id": "d9b919e4-1fc4-4545-b43b-cc4951f00bbe",
      "url": "https://strikemag.org/bullshit-jobs/",
      "type": "article",
      "title": "STRIKE! Magazine – On the Phenomenon of Bullshit Jobs: A Work Rant",
      "content": "<div>\n        <p>In the year 1930, John Maynard Keynes predicted that, by century's end, technology would have advanced sufficiently that countries like Great Britain or the United States would have achieved a 15-hour work week. There's every reason to believe he was right. In technological terms, we are quite capable of this. And yet it didn't happen. Instead, technology has been marshaled, if anything, to figure out ways to make us all work more. In order to achieve this, jobs have had to be created that are, effectively, pointless. Huge swathes of people, in Europe and North America in particular, spend their entire working lives performing tasks they secretly believe do not really need to be performed. The moral and spiritual damage that comes from this situation is profound. It is a scar across our collective soul. Yet virtually no one talks about it.</p>\n<p>Why did Keynes' promised utopia—still being eagerly awaited in the '60s—never materialise? The standard line today is that he didn't figure in the massive increase in consumerism. Given the choice between less hours and more toys and pleasures, we've collectively chosen the latter. This presents a nice morality tale, but even a moment's reflection shows it can't really be true. Yes, we have witnessed the creation of an endless variety of new jobs and industries since the '20s, but very few have anything to do with the production and distribution of sushi, iPhones, or fancy sneakers.</p>\n<p>So what are these new jobs, precisely? A recent report comparing employment in the US between 1910 and 2000 gives us a clear picture (and I note, one pretty much exactly echoed in the UK). Over the course of the last century, the number of workers employed as domestic servants, in industry, and in the farm sector has collapsed dramatically. At the same time, ‘professional, managerial, clerical, sales, and service workers’ tripled, growing ‘from one-quarter to three-quarters of total employment.’ In other words, productive jobs have, just as predicted, been largely automated away (even if you count industrial workers globally, including the toiling masses in India and China, such workers are still not nearly so large a percentage of the world population as they used to be.)</p>\n<p>But rather than allowing a massive reduction of working hours to free the world's population to pursue their own projects, pleasures, visions, and ideas, we have seen the ballooning of not even so much of the ‘service’ sector as of the administrative sector, up to and including the creation of whole new industries like financial services or telemarketing, or the unprecedented expansion of sectors like corporate law, academic and health administration, human resources, and public relations. And these numbers do not even reflect on all those people whose job is to provide administrative, technical, or security support for these industries, or for that matter the whole host of ancillary industries (dog-washers, all-night pizza delivery) that only exist because everyone else is spending so much of their time working in all the other ones.</p>\n<p>These are what I propose to call ‘bullshit jobs’.</p>\n<p>It's as if someone were out there making up pointless jobs just for the sake of keeping us all working. And here, precisely, lies the mystery. In capitalism, this is precisely what is not supposed to happen. Sure, in the old inefficient socialist states like the Soviet Union, where employment was considered both a right and a sacred duty, the system made up as many jobs as they had to (this is why in Soviet department stores it took three clerks to sell a piece of meat). But, of course, this is the sort of very problem market competition is supposed to fix. According to economic theory, at least, the last thing a profit-seeking firm is going to do is shell out money to workers they don't really need to employ. Still, somehow, it happens.</p>\n<p>While corporations may engage in ruthless downsizing, the layoffs and speed-ups invariably fall on that class of people who are actually making, moving, fixing and maintaining things; through some strange alchemy no one can quite explain, the number of salaried paper-pushers ultimately seems to expand, and more and more employees find themselves, not unlike Soviet workers actually, working 40 or even 50 hour weeks on paper, but effectively working 15 hours just as Keynes predicted, since the rest of their time is spent organizing or attending motivational seminars, updating their facebook profiles or downloading TV box-sets.</p>\n<p>The answer clearly isn't economic: it's moral and political. The ruling class has figured out that a happy and productive population with free time on their hands is a mortal danger (think of what started to happen when this even began to be approximated in the '60s). And, on the other hand, the feeling that work is a moral value in itself, and that anyone not willing to submit themselves to some kind of intense work discipline for most of their waking hours deserves nothing, is extraordinarily convenient for them.</p>\n<p>Once, when contemplating the apparently endless growth of administrative responsibilities in British academic departments, I came up with one possible vision of hell. Hell is a collection of individuals who are spending the bulk of their time working on a task they don't like and are not especially good at. Say they were hired because they were excellent cabinet-makers, and then discover they are expected to spend a great deal of their time frying fish. Neither does the task really need to be done—at least, there's only a very limited number of fish that need to be fried. Yet somehow, they all become so obsessed with resentment at the thought that some of their co-workers might be spending more time making cabinets, and not doing their fair share of the fish-frying responsibilities, that before long there's endless piles of useless badly cooked fish piling up all over the workshop and it's all that anyone really does. I think this is actually a pretty accurate description of the moral dynamics of our own economy.</p>\n<p>Now, I realise any such argument is going to run into immediate objections: ‘who are you to say what jobs are really “necessary”? What's necessary anyway? You're an anthropology professor, what's the “need” for that?’ (And indeed a lot of tabloid readers would take the existence of my job as the very definition of wasteful social expenditure.) And on one level, this is obviously true. There can be no objective measure of social value.</p>\n<p>I would not presume to tell someone who is convinced they are making a meaningful contribution to the world that, really, they are not. But what about those people who are themselves convinced their jobs are meaningless? Not long ago I got back in touch with a school friend who I hadn't seen since I was 12. I was amazed to discover that in the interim, he had become first a poet, then the front man in an indie rock band. I'd heard some of his songs on the radio having no idea the singer was someone I actually knew. He was obviously brilliant, innovative, and his work had unquestionably brightened and improved the lives of people all over the world. Yet, after a couple of unsuccessful albums, he'd lost his contract, and plagued with debts and a newborn daughter, ended up, as he put it, ‘taking the default choice of so many directionless folk: law school.’ Now he's a corporate lawyer working in a prominent New York firm. He was the first to admit that his job was utterly meaningless, contributed nothing to the world, and, in his own estimation, should not really exist.</p>\n<p>There's a lot of questions one could ask here, starting with, what does it say about our society that it seems to generate an extremely limited demand for talented poet-musicians, but an apparently infinite demand for specialists in corporate law? (Answer: if 1% of the population controls most of the disposable wealth, what we call ‘the market’ reflects what they think is useful or important, not anybody else.) But even more, it shows that most people in these jobs are ultimately aware of it. In fact, I'm not sure I've ever met a corporate lawyer who didn't think their job was bullshit. The same goes for almost all the new industries outlined above. There is a whole class of salaried professionals that, should you meet them at parties and admit that you do something that might be considered interesting (an anthropologist, for example), will want to avoid even discussing their line of work entirely (one or t'other?) Give them a few drinks, and they will launch into tirades about how pointless and stupid their job really is.</p>\n<p>This is a profound psychological violence here. How can one even begin to speak of dignity in labour when one secretly feels one's job should not exist? How can it not create a sense of deep rage and resentment. Yet it is the peculiar genius of our society that its rulers have figured out a way, as in the case of the fish-fryers, to ensure that rage is directed precisely against those who actually do get to do meaningful work. For instance: in our society, there seems a general rule that, the more obviously one's work benefits other people, the less one is likely to be paid for it. Again, an objective measure is hard to find, but one easy way to get a sense is to ask: what would happen were this entire class of people to simply disappear? Say what you like about nurses, garbage collectors, or mechanics, it's obvious that were they to vanish in a puff of smoke, the results would be immediate and catastrophic. A world without teachers or dock-workers would soon be in trouble, and even one without science fiction writers or ska musicians would clearly be a lesser place. It's not entirely clear how humanity would suffer were all private equity CEOs, lobbyists, PR researchers, actuaries, telemarketers, bailiffs or legal consultants to similarly vanish. (Many suspect it might markedly improve.) Yet apart from a handful of well-touted exceptions (doctors), the rule holds surprisingly well.</p>\n<p>Even more perverse, there seems to be a broad sense that this is the way things should be. This is one of the secret strengths of right-wing populism. You can see it when tabloids whip up resentment against tube workers for paralysing London during contract disputes: the very fact that tube workers can paralyse London shows that their work is actually necessary, but this seems to be precisely what annoys people. It's even clearer in the US, where Republicans have had remarkable success mobilizing resentment against school teachers, or auto workers (and not, significantly, against the school administrators or auto industry managers who actually cause the problems) for their supposedly bloated wages and benefits. It's as if they are being told ‘but you get to teach children! Or make cars! You get to have real jobs! And on top of that you have the nerve to also expect middle-class pensions and health care?’</p>\n<p>If someone had designed a work regime perfectly suited to maintaining the power of finance capital, it's hard to see how they could have done a better job. Real, productive workers are relentlessly squeezed and exploited. The remainder are divided between a terrorised stratum of the, universally reviled, unemployed and a larger stratum who are basically paid to do nothing, in positions designed to make them identify with the perspectives and sensibilities of the ruling class (managers, administrators, etc.)—and particularly its financial avatars—but, at the same time, foster a simmering resentment against anyone whose work has clear and undeniable social value. Clearly, the system was never consciously designed. It emerged from almost a century of trial and error. But it is the only explanation for why, despite our technological capacities, we are not all working 3–4 hour days.</p>\n        <div>\n            <figure>\n              <a href=\"http://strikemag.bigcartel.com/product/strike-anthology-1-8\">\n                <img src=\"https://strikemag.org/thumbs/magazine/issue-3/03-spread-01-500x684-q100.jpg\" alt=\"STRIKE! Issue 3\">\n              </a>\n              <figcaption>\n                Printed in Issue 3 The Summer&nbsp;Of...                  <p>\n                  <a href=\"http://strikemag.bigcartel.com/product/strike-anthology-1-8\">Get it here</a></p></figcaption>\n            </figure>\n          </div>\n      </div>",
      "author": "@strikeyo",
      "description": "",
      "dateAdded": "2025-02-18T08:07:23.060Z",
      "media": {
        "images": [
          {
            "url": "https://strikemag.org/content/2-magazine/20130817-issue-3/20130817-bullshit-jobs/bullshitjobs.jpg",
            "alt": "STRIKE! Magazine – On the Phenomenon of Bullshit Jobs: A Work Rant",
            "isHero": true
          }
        ],
        "videos": []
      }
    },
    {
      "id": "c1e75e5f-de10-4cd7-8e43-0a1e4d69b280",
      "url": "https://beneaththepavement.substack.com/p/you-will-never-be-a-billionaire",
      "type": "article",
      "title": "You will never be a billionaire you stupid fuck",
      "content": "<div><p><strong>You honestly believe you might get there one day, don’t you?</strong></p><p>That if you just grind hard enough, hustle longer, keep your nose to the never-ending wheel, snort some cocaine, you’ll strike gold—some multi-million-dollar jackpot that will escalate your life into the billionaire orbit. You’ll buy mansions, fly private, land a feature in Forbes, and the whole world will finally see you for the visionary you are.</p><p><span>THEY WILL SEE YOU FOR WHAT YOU’VE ALWAYS BEEN. A STRONG MAN, AN ABLE MAN. </span><strong>THE PEAK OF MOTHERFUCKING MASCULINITY.</strong></p><p><span>Let me cut the shit for you: </span><strong>You will never be a billionaire.</strong><span> You are not part of the club. You never were, never will be. The entire system you’re propping up with sweat, blood, time, dignity—</span><em>your whole fucking life</em><span>—has zero intention of letting you ascend the throne. It doesn’t matter how many motivational posters you pin on your depressing cubicle wall, or how many times you read think pieces about “10 Habits of Self-Made Millionaires.” The biggest con capitalism ever sold you is the idea that you, too, can become one of the overlords.</span></p><p><span>Yet you cannot accept. </span><strong>YOU MUST BE ONE OF THEM.</strong></p><p><span>You wake at dawn, hustle to two or three jobs, and blame yourself when it doesn’t pan out. You internalize every self-help seminar, every YouTube “guru” telling you to “manifest that dream,” because if you fail, it must be your fault, right? You just need more grit, more devotion. Guess what? None of that hustle is going to breach the golden gates. Their wealth is compounding at obscene rates, while you’re drowning in monthly bills, credit card debt, and groceries that used to cost half of what they do now. Wages barely rise an inch, but the cost of everything else skyrockets like a fucking rocket fueled by your regrets. </span><strong>They humiliate you, keep you down, and yet you keep licking those delicious boots</strong><span>, slowly turning into what you always wanted to be: a fascist. The ultimate power fantasy of the weak man.</span></p><p><span>The US is especially adept at selling these lies. </span><strong>The American Dream is the biggest farce of them all.</strong><span> It’s a centuries-old propaganda machine perpetuated to keep you docile, keep you striving. Because the moment you realize you’re not actually going to make it into their exclusive club, you might do the unthinkable:</span></p><p><strong>Link arms with others in your position, your sisters and brothers in arms, start asking uncomfortable questions, start demanding real change, start tearing this shit down!</strong></p><p><span>And they can’t have that. </span><em>They absolutely cannot have that</em><span>. It’s so much easier to feed you illusions of grandeur, illusions of that house with a picket fence, three perfect blonde children, and the brand-new Tesla in your driveway, illusions that your hard work and moral fortitude will pay off.</span></p><p><span>It’s an </span><strong>exclusive club</strong><span>. They’re born into it. They marry into it. Occasionally, they let in a freak example of the “self-made” billionaire just to keep the whole ruse going—like a grand carnival trick, a lottery winner who makes the rest of us keep buying tickets. But this system was never meant to elevate you. It was made to keep you hoping, praying, and slogging along in your bullshit job, saturating your mind with fantasies of “one day.”</span></p><p><strong>One day, one day, one day you will ascend. You will join them, dine with them, fuck their rich daughters, laugh at the dying peasants beneath your throne.</strong></p><p>You never realize they’re all fucking losers, and so are you.</p><p><span>Meanwhile, the wealth gap keeps widening. The top 1% hoard more and more, passing it on to their heirs, who, in turn, pass it on to theirs, and so forth, building a perpetual harem of obscene riches. They’ve got real estate in every major and minor city, stashed away trust funds, offshore accounts, private islands, entire corners of the planet as personal playgrounds—</span><strong>while you can barely afford the rent on your leaky apartment</strong><span>. They don’t give a fuck about you. Why would they? You’re a disposable cog in </span><em>their</em><span> profit machine. You exist to keep the system afloat, not to question it. You are an embarrassment.</span></p><p><strong>You have more in common with the homeless person on the street</strong><span> than with the lords of capital. </span><strong>Read that again.</strong><span> Yet you’re fed a narrative that the homeless are lazy, or that they “chose” their fate, while the billionaire is a shining beacon of entrepreneurial success. </span><strong>Wake the fuck up, samurai.</strong><span> There’s a reason they’re sinking millions into PR campaigns and philanthropic vanity projects: to maintain the illusion of being “good guys,” so you won’t unite against them in a glorious storm of ultra-violent class solidarity.</span></p><p>It’s so easy to blame yourself for not working hard enough. It’s so easy to idolize people like Elon Musk or Jeff Bezos or Donald Trump, to retweet their “inspiring” quotes or watch their interviews like they’re prophets of some new fucked up religion. We got enough of those. They’re playing you. They suck up obscene wealth created by countless workers—warehouse workers pissing in bottles, gig drivers sleeping in their cars, lab researchers on short-term contracts, engineers burning out daily, the poor and homeless always a warning—and then toss you a rotten bone.</p><p><strong>It’s time to burn that entire dream to the ground</strong><span>—not your own dreams, but the corporate propaganda. You want a real dream? Dream of a world where you’re not paying half your paycheck to a landlord who’s never fixed a thing in your apartment. Dream of a society where you don’t have to decide between medical treatment or feeding your kids. Dream of a community that invests in your well-being, your education, your mental health. Dream of a world that doesn’t slaughter innocents. Dream of a world where ALL share the fruits of progress. Dream of </span><strong>true liberty</strong><span>: freedom from the shackles of wage labor, from the desperation that compels you to bow your head and accept humiliation.</span></p><p><span>Dream, if not for you, for the countless others. Even if you do not suffer, even if you’re comfortable, all </span><em>that </em><span>is built on the suffering of others.</span></p><p><span>They’ve convinced you that the system’s rigged in your favor (with a little elbow grease), when in truth, it’s rigged </span><em>against</em><span> you from the second you’re born without generational wealth. This is a system built by them, </span><em>for them</em><span>. They taught you to look down on those below you rather than </span><strong>question why the fuck there’s a ladder in the first place.</strong><span> They taught you to scratch and claw your way up the rung, fighting others for the measly scraps. Meanwhile, the top rung is locked behind a gate that’s guarded by an army of lawyers, lobbyists, PR experts, and politicians on their payroll.</span></p><p><strong>Think about it</strong><span>: every time you see some working-class person praising the billionaire’s success story, doesn’t it feel like they’re praising a jailer for building a slightly bigger cell? We need to break the fuck free, not admire the shiny steel bars. This planet is set ablaze by their industries, oceans choked with plastic from their profit-driven shipping. They hoard resources and then preach charity as if they’re doing us a favor. And you keep chasing their acceptance, their lifestyle, as if it’s the promised land. It’s not. It’s a labyrinth rigged with illusions and soul-sucking corridors.</span></p><p><strong>Class solidarity</strong><span> is the only way out. Stop idolizing those rich cunts and start standing with those by your side. You’re not going to buy a one-way ticket to the top of the pyramid. Start building real bonds with people who also struggle with rent, medical bills, student loans, child care, soul-crushing office jobs, gig-economy chaos, the entire dystopian hamster wheel. You’ll realize the power has always been with the collective—</span><em>if</em><span> we decide to wield it. If we refuse to be pitted against each other by bullshit identity wars and blame games.</span></p><p><strong>Yes, it’s a revolution we need</strong><span>—a revolution of perspective, a revolution of the heart, and, down the line, a revolution in more tangible ways. Because you’re never going to change this system by playing its game, or by valiantly “working your way up.” And they are counting on you to keep believing that lie because it keeps you docile. It keeps you from storming the gates. It keeps you from pulling that entire facade down.</span></p><p><span>But look, you still have a choice, right here, right now: keep hustling for their scraps, keep your illusions alive and be disappointed for the rest of your life, or </span><strong>stand the fuck up</strong><span> and say: “Enough.” </span><strong>Demand better.</strong><span> Not just for yourself, but for everyone on this sinking ship. Demand an end to wage slavery, to exploitation, to the idea that you should sacrifice everything for some unattainable dream. Demand genuine democracy, not a capitalist democracy that’s bought and paid for by the highest bidder. Demand transparency. Demand the wealth that should belong to society, not to a handful of oligarchs playing Monopoly with our lives. </span><strong>Demand liberty</strong><span>, real liberty—the kind that sets your mind on fire and your heart pounding with possibility.</span></p><p><span>It’s time for you to grow up. Time for you to use your brain. </span><strong>Time to stop the daily humiliation.</strong><span> You are so fragile, so weak, so easily manipulated in your laughable attempts at domination and control. You wanna be a real man? A real man isn’t scared of ghosts; isn’t scared of minorities, isn’t scared of women having the same fucking rights as men, isn’t scared of complexity. Why the fuck are you always so scared?</span></p><p><span>You will never be a billionaire. They don’t want you. They never did. Show some fucking class—</span><em><strong>class consciousness</strong></em><span>—and turn that anger, that yearning, that energy toward solidarity with the rest of us stuck in the trenches. </span><strong>EVERY SINGLE ONE OF US.</strong><span> Stop believing them when they tell you that skin color, gender, nationality, religion, </span><em>anything</em><span> matters. You have believed too long. There’s us and them, nothing else. Just think, for fuck’s sake. </span><strong>How much more propaganda can you swallow?</strong><span> They’re laughing at our division, so very carefully orchestrated, they’re laughing at you. From their golden thrones, they are laughing.</span></p><p><strong>And the world stands at the abyss.</strong></p><p>Antonio</p><p><a href=\"https://www.amazon.com/stores/Antonio-Melonio/author/B0BRH6ZSTK\">Read my books</a><span>, if you haven’t done so yet. They’re all about revolution and anger. If you like my work, you can become a paid subscriber here on Substack or you can support me on </span><a href=\"https://www.patreon.com/c/antoniomelonio\">Patreon</a><span> and via </span><a href=\"https://www.paypal.com/paypalme/melonioantonio\">PayPal</a><span>. Thank you.</span></p><p>“Enjoy” this essay in video format:</p><div><p></p></div></div>",
      "author": "Antonio Melonio",
      "description": "",
      "dateAdded": "2025-01-29T18:09:16.000Z",
      "media": {
        "images": [
          {
            "url": "https://substackcdn.com/image/fetch/f_auto,q_auto:best,fl_progressive:steep/https%3A%2F%2Fbeneaththepavement.substack.com%2Fapi%2Fv1%2Fpost_preview%2F155937294%2Ftwitter.jpg%3Fversion%3D4",
            "alt": "You will never be a billionaire you stupid fuck",
            "isHero": true
          }
        ],
        "videos": []
      }
    }
  ]
}